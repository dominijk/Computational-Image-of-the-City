{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox, networkx as nx, matplotlib.cm as cm, pandas as pd, numpy as np, geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import functools\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('precision', 5)\n",
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import landmarks_functions as lf\n",
    "import utilities as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'landmarks_functions' from 'C:\\\\Users\\\\g_filo01\\\\sciebo\\\\scripts\\\\Image of the City\\\\landmarks_functions.py'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing landmarkness on paths and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise path, names, etc.\n",
    "\n",
    "city_name = 'London'\n",
    "folder_ouptut ='Outputs/'+city_name+'/'\n",
    "epsg = 27700\n",
    "crs = {'init': 'epsg:27700', 'no_defs': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try reading nodes, paths, landmarks and sight_lines\n",
    "# At this point, every element has already been extracted\n",
    "\n",
    "nodes = gpd.read_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')\n",
    "paths = gpd.read_file(folder_ouptut+city_name+'_paths.shp', driver='ESRI Shapefile')\n",
    "landmarks = gpd.read_file(folder_ouptut+city_name+'_landmarks.shp', driver='ESRI Shapefile')\n",
    "sight_lines = gpd.read_file(folder_ouptut+city_name+'_sightlines.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Local salience landmarks and assigning scores to Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "landmarks = lf.local_scores(landmarks, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes = lf.local_salience(nodes, landmarks)\n",
    "nodes = lf.distant_landmarks(nodes, landmarks, sight_lines, smaller_area = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 99 %Wall time: 3h 21min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# nodes_2dvis_field = ic.advance_visibility_nodes(nodes, paths, landmarks, field_view = True)\n",
    "nodes_2dvis = lf.advance_visibility_nodes(nodes, paths, landmarks, field_view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_matrix = lf.visibility_matrix(landmarks, nodes_2dvis, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_matrix.to_csv(folder_ouptut+city_name+'_visibility_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion from lists to string, to export the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_convert = ['loc_land', 'loc_scor', 'dist_land', 'dist_scor', 'anchors']\n",
    "nodes_string = nodes.copy()\n",
    "for column in to_convert: nodes_string[column] = nodes_string[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_string.to_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = vm.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.nodeID.values.tolist() == t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8871"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing edge betweenness \n",
    "## Primal graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_graph = nodes[['x', 'y', 'nodeID', 'DD_sc', 'geometry']]\n",
    "nodes_graph.gdf_name = 'Nodes_list' #for OSMNx\n",
    "\n",
    "attributes_nodes = ['DD_sc', 'geometry']\n",
    "edges_costs = ['length', 'length_sc']\n",
    "\n",
    "G = ic.graph_fromGDF(nodes_graph, paths, attributes_nodes, edges_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "from networkx import NetworkXError\n",
    "import networkx as nx\n",
    "\n",
    "def astar_path(G, source, target, nodes_gdf, landmarks_gdf, weight=None):\n",
    " \n",
    "    if G.is_multigraph():\n",
    "        raise NetworkXError(\"astar_path() not implemented for Multi(Di)Graphs\")\n",
    "\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    sindex = landmarks_gdf.sindex\n",
    "    index_lScore = landmarks_gdf.columns.get_loc(\"lScore\")+1\n",
    "    index_geometry = landmarks_gdf.columns.get_loc(\"geometry\")+1\n",
    "    index_buildingID = landmarks_gdf.columns.get_loc(\"buildingID\")+1\n",
    "    \n",
    "    # The queue stores priority, node, cost to reach, and parent.\n",
    "    # Uses Python heapq to keep in priority order.\n",
    "    # Add a counter to the queue to prevent the underlying heap from\n",
    "    # attempting to compare the nodes themselves. The hash breaks ties in the\n",
    "    # priority and is guarenteed unique for all nodes in the graph.\n",
    "    c = count()\n",
    "    queue = [(0, next(c), source, 0, None)] # openSet\n",
    "    \n",
    "    enqueued = {}\n",
    "    # Maps explored nodes to parent closest to the source.\n",
    "    explored = {}\n",
    "\n",
    "    while queue:\n",
    "        # Pop the smallest item from queue.\n",
    "        _, __, current_node, cost_so_far, coming_from = pop(queue)\n",
    "    \n",
    "        if current_node == target: #construct path\n",
    "            path = [current_node]\n",
    "            node = coming_from\n",
    "            while node is not None:\n",
    "                path.append(node)\n",
    "                node = explored[node]\n",
    "            path.reverse()\n",
    "            return path\n",
    "        \n",
    "\n",
    "        if current_node in explored: continue\n",
    "        explored[current_node] = coming_from\n",
    "        for nodeTarget, edgeAtt in G[current_node].items():\n",
    "            \n",
    "            if nodeTarget in explored: continue\n",
    "\n",
    "            index_landmarks_at_node = nodes_gdf['landmarks'][nodes_gdf['nodeID'] == G.node[nodeTarget]['nodeID']].tolist()[0]\n",
    "            \n",
    "            \n",
    "            if (isinstance(index_landmarks_at_node, list) == False): lScore_total = 1\n",
    "            \n",
    "            else:\n",
    "                landmarks_at_node = landmarks_gdf[landmarks_gdf.buildingID.isin(index_landmarks_at_node)]\n",
    "\n",
    "                geometry_node = G.node[nodeTarget]['geometry']\n",
    "\n",
    "                lScore_total = 0\n",
    "\n",
    "                for row in landmarks_at_node.itertuples():\n",
    "\n",
    "                    cumulative_AdvanceVis = 0    \n",
    "                    distance_travelled = 0\n",
    "                    nodeTo =  nodeTarget\n",
    "                    nodeFrom = current_node\n",
    "\n",
    "                    while ((nodeFrom is not None) & (distance_travelled <= 200)):\n",
    "\n",
    "                            nodeColumn = str(nodeFrom)\n",
    "                            visible = visibility_matrix[visibility_matrix['buildingID']==row[index_buildingID]][nodeColumn].tolist()[0]\n",
    "                            \n",
    "                            if visible == True: cumulative_AdvanceVis = cumulative_AdvanceVis + G[nodeFrom][nodeTo]['length'] \n",
    "                            distance_travelled = distance_travelled + G[nodeFrom][nodeTo]['length']\n",
    "                            nodeTo = nodeFrom\n",
    "                            nodeFrom = explored[nodeFrom]\n",
    "\n",
    "                    aV = cumulative_AdvanceVis/distance_travelled\n",
    "                    tmp = row[index_lScore] * aV\n",
    "\n",
    "                    if tmp > lScore_total: lScore_total = tmp\n",
    "            \n",
    "            node_DD_score = G.node[nodeTarget]['DD_sc']\n",
    "            tentative = cost_so_far + edgeAtt.get(weight, 1) + (1-lScore_total) + node_DD_score\n",
    "            \n",
    "            if nodeTarget in enqueued:\n",
    "                qcost, heuristic = enqueued[nodeTarget]\n",
    "                if qcost <= cost_so_far: continue\n",
    "\n",
    "            else: heuristic = 0\n",
    "            \n",
    "            enqueued[nodeTarget] = cost_so_far, heuristic\n",
    "            push(queue, (cost_so_far + heuristic, next(c), nodeTarget, cost_so_far, current_node))\n",
    "\n",
    "    raise nx.NetworkXNoPath(\"Node %s not reachable from %s\" % (source, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ec(G, normalized = False, weight = None, seed=None):\n",
    "\n",
    "    Eb = dict.fromkeys(G.edges(), 0.0)\n",
    "    nodesT = list(dict.fromkeys(G.nodes()))\n",
    "    processed = []\n",
    "    \n",
    "    for s in     nodesT:\n",
    "\n",
    "        for t in (t for t in nodesT if s != t):\n",
    "\n",
    "            if (((s,t) in processed) & ((t,s) in processed)): continue\n",
    "            sp = astar_path(G, s, t, nodes, landmarks, weight=weight)\n",
    "            \n",
    "            for i, n in enumerate(sp):\n",
    "                if i == 0: continue\n",
    "                else: path = (sp[i], sp[i-1])\n",
    "\n",
    "                if path in Eb: path = path\n",
    "                else: path = (sp[i-1], sp[i])\n",
    "\n",
    "                Eb[path] += 1\n",
    "                \n",
    "    return Eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t = ec(G, normalized = False, weight = 'lenght_sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_source_dijkstra_path_basic(G, s, weight):\n",
    "    # modified from Eppstein\n",
    "    S = []\n",
    "    P = {}\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    seen = {s: 0}\n",
    "    c = count()\n",
    "    Q = []   # use Q as heap with (distance,node id) tuples\n",
    "    push(Q, (0, next(c), s, s))\n",
    "    while Q:\n",
    "        (dist, _, pred, v) = pop(Q)\n",
    "        if v in D:\n",
    "            continue  # already searched this node.\n",
    "        sigma[v] += sigma[pred]  # count paths\n",
    "        S.append(v)\n",
    "        D[v] = dist\n",
    "        for w, edgedata in G[v].items():\n",
    "            vw_dist = dist + edgedata.get(weight, 1)\n",
    "            if w not in D and (w not in seen or vw_dist < seen[w]):\n",
    "                seen[w] = vw_dist\n",
    "                push(Q, (vw_dist, next(c), v, w))\n",
    "                sigma[w] = 0.0\n",
    "                P[w] = [v]\n",
    "            elif vw_dist == seen[w]:  # handle equal paths\n",
    "                sigma[w] += sigma[v]\n",
    "                P[w].append(v)\n",
    "    return S, P, sigma\n",
    "\n",
    "def et(G, k=None, normalized=True, weight=None):\n",
    "    betweenness = dict.fromkeys(G, 0.0)  # b[v]=0 for v in G\n",
    "    # b[e]=0 for e in G.edges()\n",
    "    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n",
    "    \n",
    "    nodes = G\n",
    "\n",
    "    for s in nodes:\n",
    "        S, P, sigma = _single_source_dijkstra_path_basic(G, s, weight)\n",
    "        print(S, '------------------')\n",
    "        print(P, '------------------')\n",
    "        print(sigma, '------------------')\n",
    "        # accumulation\n",
    "        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n",
    "        break\n",
    "    # rescaling\n",
    "    for n in G:  # remove nodes to only return edges\n",
    "        del betweenness[n]\n",
    "    \n",
    "    betweenness = _rescale_e(betweenness, len(G), normalized=normalized,\n",
    "                             directed=G.is_directed())\n",
    "    return betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et(G, normalized = True, weight = 'length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb = dict.fromkeys(G.edges(), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for t in G.edges(): edges.append(t)\n",
    "dict_edges = {k: 0 for v, k in enumerate(edges)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = nx.astar_path(G, 1, 2, weight='length')\n",
    "sp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lb = nx.edge_betweenness_centrality(Ng, weight='land_sc', normalized=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELb = nx.edge_betweenness_centrality(Ng, weight='dist&land', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab_df = ic.dict_to_df([Lb, ELb, edge_id], [\"Lb\", \"ELb\",\"streetID\"])\n",
    "paths_tmp = pd.merge(paths, edges_df, left_on = 'streetID', right_on = 'streetID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_id={}\n",
    "for i, g in Ng.edges(): edge_id[(i,g)]=Ng[i][g]['streetID']\n",
    "\n",
    "edges_df = to_df([Lb, ELb, edge_id], [\"Lb\", \"ELb\",\"streetID\"])\n",
    "edges_df.streetID = edges_df.streetID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.plotGDF(paths_tmp,'Eb', 'Euclidean Betweenness')\n",
    "ic.plotGDF(paths_tmp,'Lb', 'Landmark Betweenness')\n",
    "ic.plotGDF(paths_tmp,'ELb', 'Landmark and distance Betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "nodes.plot(ax=ax, column='dist', cmap='OrRd', scheme='Fisher_Jenks', markersize=5)\n",
    "plt.axis('equal')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dual = gpd.read_file(folder_ouptut+city_name+'_nodesDual.shp', driver='ESRI Shapefile')\n",
    "edges_dual = gpd.read_file(folder_ouptut+city_name+'_edgesDual.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning landmark scores to links between centroids (this is artificial)\n",
    "\n",
    "edges_dual.u = edges_dual.u.astype(int)\n",
    "edges_dual.v = edges_dual.v.astype(int)\n",
    "edges_dual.key = edges_dual.key.astype(int)\n",
    "\n",
    "for row in edges_dual.itertuples():\n",
    "    landmarkness_u = paths['land'][paths.streetID==row[1]].loc[row[1]] #row[1]==u\n",
    "    landmarkness_v = paths['land'][paths.streetID==row[2]].loc[row[2]] #row[2]==v\n",
    "    landmarkness = landmarkness_u+landmarkness_v\n",
    "    edges_dual.set_value(row[0], 'land', landmarkness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.scaling_columnDF(edges_dual, 'rad')\n",
    "ic.scaling(edges_dual, 'land') \n",
    "edges_dual['angle&land'] = edges_dual['rad_sc']+edges_dual['land_sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dual.gdf_name = 'Dual_list'\n",
    "Gr = ox.gdfs_to_graph(nodes_dual, edges_dual)\n",
    "    \n",
    "n = Gr.nodes()\n",
    "pos = {}\n",
    "    \n",
    "print(len(n))\n",
    "for l, item in enumerate(n): pos[l] = (n[l]['x'],n[l]['y'],n[l]['streetID'])\n",
    "        \n",
    "DG = nx.Graph() #Empty graph\n",
    "DG = DG.to_undirected()\n",
    "DG.add_nodes_from(pos.keys()) #Add nodes preserving coordinates\n",
    "    \n",
    "for i, item in enumerate(DG.nodes()):\n",
    "    DG.node[i]['x']=pos[i][0]\n",
    "    DG.node[i]['y']=pos[i][1]\n",
    "    DG.node[i]['streetID']=pos[i][2]\n",
    "        \n",
    "for i, item in enumerate(Gr.edges()):\n",
    "    DG.add_edge(item[0], item[1])\n",
    "    DG[item[0]][item[1]]['angle&land'] = Gr[item[0]][item[1]][0]['angle&land']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALb = nx.betweenness_centrality(DG, weight='angle&land', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_dict(ed, graph):\n",
    "    \n",
    "    view = ed.items()\n",
    "    ed_list = list(view)\n",
    "    ed_dict = {}\n",
    "\n",
    "    for p in ed_list:\n",
    "        ed_dict[graph.node[p[0]]['streetID']]=p[1] #streetID and Edge betweenness\n",
    "        \n",
    "    return(ed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALb_dict = id_dict(ALb, DG)\n",
    "ALb_df = to_df([ALb_dict], [\"ALb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp = pd.merge(paths_tmp, ALb_df, left_on=\"streetID\", right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(paths_tmp,'Ab', 'Angular Betweenness')\n",
    "plot(paths_tmp,'ALb', 'Angular-Landmark Betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.to_file(folder_ouptut+city_name+'_experiment_paths.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.drop(['visible_landmarks'], axis=1).to_file(folder_ouptut+city_name+'_experiment_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians = pd.read_csv(\"C:/Users/g_filo01/sciebo/GIS Data/Simulation/London_pedestrian_counts_27-08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = gpd.read_file(\"C:/Users/g_filo01/sciebo/Scripts/Image of the City/Outputs/London/London_pedestrians_count.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2 = pp[['geometry', 'streetID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2 = pd.merge(pp2, pedestrians, left_on=\"streetID\", right_on=\"streetID\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>streetID</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>topological</th>\n",
       "      <th>angular</th>\n",
       "      <th>euclideanLand</th>\n",
       "      <th>topologicalLand</th>\n",
       "      <th>angularLand</th>\n",
       "      <th>landmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINESTRING (528421.0000001118 180948.999999571...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINESTRING (533740.0500001372 181263.939999453...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>450</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>408</td>\n",
       "      <td>93</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINESTRING (533835.3200001377 180907.189999451...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>214</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>113</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINESTRING (528136.0000001106 180780.999999577...</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>263</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>511</td>\n",
       "      <td>36</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINESTRING (532764.1500001322 180312.289999477...</td>\n",
       "      <td>4</td>\n",
       "      <td>426</td>\n",
       "      <td>322</td>\n",
       "      <td>603</td>\n",
       "      <td>491</td>\n",
       "      <td>307</td>\n",
       "      <td>627</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  streetID  euclidean  \\\n",
       "0  LINESTRING (528421.0000001118 180948.999999571...         0          2   \n",
       "1  LINESTRING (533740.0500001372 181263.939999453...         1         30   \n",
       "2  LINESTRING (533835.3200001377 180907.189999451...         2         28   \n",
       "3  LINESTRING (528136.0000001106 180780.999999577...         3         79   \n",
       "4  LINESTRING (532764.1500001322 180312.289999477...         4        426   \n",
       "\n",
       "   topological  angular  euclideanLand  topologicalLand  angularLand  landmark  \n",
       "0           17        6              2               19            3        23  \n",
       "1          450      118             10              408           93       535  \n",
       "2          214      119             10              196          113       265  \n",
       "3          263       37             17              511           36       475  \n",
       "4          322      603            491              307          627       314  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2.to_file(folder_ouptut+city_name+'_pedestrians_count.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians = pd.read_csv(\"C:/Users/g_filo01/sciebo/GIS Data/Simulation/pedestrians_eucl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colPed = [\"euclidean\", \"topological\", \"angular\", \"landmark\", \"euclideanLand\", \"topologicalLand\", \"angularLand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data = pd.merge(paths_tmp, pedestrians, left_on=\"streetID\", right_on=\"streetID\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data['euclideanDiff']=paths_data['euclidean']-paths_data['euclideanLand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotGDF(paths_data,\"euclidean\",\"euclidean\")\n",
    "# plotGDF(paths_data,\"topological\",\"topological\")\n",
    "# plotGDF(paths_data,\"angular\",\"angular\")\n",
    "plotGDF(paths_data,\"euclideanLand\",\"euclideanLand\")\n",
    "plotGDF(paths_data,\"euclideanDiff\",\"diff\")\n",
    "# plotGDF(paths_data,\"topologicalLand\",\"topologicalLand\")\n",
    "# plotGDF(paths_data,\"angularLand\",\"angularLand\")\n",
    "# plotGDF(paths_data,\"landmark\",\"landmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in colPed:\n",
    "    print(i)\n",
    "    plotGDF(paths_data, colPed, colPed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grad_GDF(paths, 'length_sc', 'll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point(mapping(landmarks.loc[5].geometry)['coordinates'][0][0]).intersects(landmarks.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbor, w in G[2].items():\n",
    "    print(neighbor, \" lll \",w)\n",
    "    print(G.node[neighbor]['DD_sc'])\n",
    "    \n",
    "    list landmarks\n",
    "    print\n",
    "    \n",
    "    print(G.node[neighbor]['DE_sc'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astar_path(G, 1, 2, landmarks, weight='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = gpd.read_file(\"C:/Users/g_filo01/sciebo/GIS Data/Torino/Turin_edges_data.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        object\n",
       "osmid       object\n",
       "edgeID       int64\n",
       "name_2      object\n",
       "num         object\n",
       "perc        object\n",
       "geometry    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.to_file(folder_ouptut+city_name+'Turin_edges_data.shp', driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
