{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox, networkx as nx, matplotlib.cm as cm, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import functools\n",
    "import community\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg\n",
    "import time\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, mapping, MultiLineString\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "pd.set_option('precision', 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_city_functions as ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise path, names, etc.\n",
    "\n",
    "city_name = 'London'\n",
    "folder_ouptut ='Outputs/'+city_name+'/'\n",
    "epsg = 27700\n",
    "crs = {'init': 'epsg:27700', 'no_defs': True}\n",
    "\n",
    "# city_name = 'Boston'\n",
    "# folder_output ='Outputs/'+city_name+'/'\n",
    "# epsg = 26986\n",
    "# crs = {'init': 'epsg:26986', 'no_defs': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the data by place or Loading shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 or 2 networks may be needed\n",
    "# Option 1 ------------\n",
    "# One graph is used (graph_A), when we consider a large area of study, e.g. an area of 10000 mt around the city centre (address). This area \n",
    "# is used or centrality measures as well as for districts extraction. Finally, edges, nodes and districts are extracted from \n",
    "# graph_A, by means of a spatial intersection, using the polygon of interest.\n",
    "\n",
    "# Option 2 ------------\n",
    "# 2 graphs: the one larger than the final area of interest, and a second one even more extended than the firs one, for a more\n",
    "# complete district extraction. Finally, edges, nodes are extracted from graph_A, districts from graph_B by means of a spatial\n",
    "# intersection, using the polygon of interest.\n",
    "\n",
    "\n",
    "Option_1 = True\n",
    "Option_2 = False\n",
    "\n",
    "download = True\n",
    "shapeFiles = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the street network is too extended for the purposes, please specify the distance from the center of the area\n",
    "# to scale down the area studied\n",
    "\n",
    "if shapeFiles = True:\n",
    "    \n",
    "    if (Option_1 == True):\n",
    "        directory_graphA = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'\n",
    "        nodes_small, edges_small = ic.get_fromSHP(directory_graphA, epsg, crs, simplify = True, area = None)\n",
    "        nodes_large, edges_large = nodes_large, edges_large   \n",
    "        polygon_clip = \n",
    "    \n",
    "    elif (Option_2 == True):\n",
    "        directory_graphA = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'\n",
    "        directory_graphB = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'\n",
    "        nodes_small, edges_small = ic.get_fromSHP(directory_graphA, epsg, crs, simplify = True, area = None)\n",
    "        # nodes_large, edges_large = ic.get_fromSHP(directory_graphB, epsg, crs, simplify = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-db8bc9b440cc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-db8bc9b440cc>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    if download = True:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if download = True:\n",
    "    \n",
    "    if (Option_1 == True):\n",
    "    \n",
    "        # choose between: (OSMplace, OSMpolygon, distance_from_address, shapefilPolygon)\n",
    "        method_A = 'distance_from_address' \n",
    "#         place_A = 'C:/Users/g_filo01/sciebo/GIS Data/London/Congestion_area_polygon/Polygon.shp'\n",
    "        place_A = 'Temple Place, London, UK'\n",
    "        nodes_small, edges_small = ic.get_fromOSM(method_A, place_A, 'walk')\n",
    "        nodes_large, edges_large = nodes_large, edges_large   \n",
    "        \n",
    "    \n",
    "    elif (Option_2 == True):\n",
    "    \n",
    "        # choose between: (OSMplace, OSMpolygon shapefilPolygon)\n",
    "        method_A = 'OSMpolygon' \n",
    "        place_A = 'C:/Users/g_filo01/sciebo/GIS Data/London/Congestion_area_polygon/Polygon.shp'\n",
    "\n",
    "\n",
    "        method_B = 'shapefilePolygon' \n",
    "        place_B = 'Greater London (175342)'\n",
    "        \n",
    "        nodes_small, edges_small = ic.get_fromOSM(method_A, place_A, 'walk')\n",
    "        nodes_large, edges_large = ic.get_fromOSM(method_B, place_B, 'walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (city_name == 'Boston'):\n",
    "    directory_small = \n",
    "    directory_large = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'\n",
    "\n",
    "else:\n",
    "    directory_small = 'C:/Users/g_filo01/sciebo/GIS Data/London/OS_Roads_Working/OS_roads_final.shp'\n",
    "    directory_large = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Street Network - gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_small, edges_small = ic.get_fromSHP(directory_small, epsg, crs)\n",
    "nodes_small, edges_small = ic.get_fromSHP(directory_small, epsg, crs, simplify = True, area = 1500)\n",
    "# nodes_large, edges_large = ic.get_fromSHP(directory_large, epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes computation - Nodes\n",
    "## only area of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = gpd.read_file(\"Outputs/\"+city_name+\"/\"+city_name+\"_paths.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_nodes = [] # besides nodeID\n",
    "edges_costs = ['length']\n",
    "\n",
    "NGs = ic.graph_fromGDF(nodes_small, edges_small, attributes_nodes, edges_costs)\n",
    "# NGl = ic.graph_fromGDF(nodes_large, edges_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bc = nx.betweenness_centrality(NGs, k=None, weight = 'length', normalized=False)\n",
    "# Sc = ic.straightness_centrality(NGs, weight = 'length', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI = gpd.read_file('Outputs/POI.shp')\n",
    "POI = (gpd.read_file(folder_ouptut+'/'+city_name+'_POI.shp')).to_crs(epsg=epsg)\n",
    "\n",
    "index_geometry = nodes_small.columns.get_loc(\"geometry\")+1\n",
    "for row in nodes_small.itertuples():\n",
    "    \n",
    "    g = row[index_geometry] #geometry\n",
    "    fil = g.buffer(50)\n",
    "    \n",
    "    sindex = POI.sindex\n",
    "    possible_matches_index = list(sindex.intersection(fil.bounds))\n",
    "    possible_matches = POI.iloc[possible_matches_index]\n",
    "        \n",
    "    weight = len(possible_matches)\n",
    "    nodes_small.set_value(row[0], 'weight', weight)\n",
    "    \n",
    "for n in NGs.nodes():\n",
    "    NGs.node[n]['weight'] = nodes_small['weight'].loc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach Centrality\n",
    "Rc400 = ic.reach_centrality(NGs, weight = 'length', radius = 400) \n",
    "Rc600 = ic.reach_centrality(NGs, weight = 'length', radius = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Betweenness Centrality\n",
    "Bc600 = ic.local_betweenness_centrality(NGs, weight = 'length', radius = 600) \n",
    "Bc400 = ic.local_betweenness_centrality(NGs, weight = 'length', radius = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = ic.dict_to_df([Bc], ['Bc'])\n",
    "nodes = pd.merge(nodes_small, nodes_df, left_on= \"nodeID\", right_index = True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [Bc, Sc, Rc400, Rc600, Bc400, Bc600]\n",
    "names = ['Bc', 'Sc', 'Rc400', 'Rc600', 'Bc400', 'Bc600']\n",
    "\n",
    "nodes_df = ic.dict_to_df(col, names)\n",
    "nodes = pd.merge(nodes_small, nodes_df, left_on= \"nodeID\", right_index = True, how='left')\n",
    "\n",
    "for i in names: ic.scaling_columnDF(nodes, i)\n",
    "nodes['height'] = 2 # for 3d visibility analysis\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.crs = crs\n",
    "nodes.to_file(folder_ouptut+city_name+'_experiment_nodes.shp', driver='ESRI Shapefile')\n",
    "# nodes_small.to_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb = nx.edge_betweenness_centrality(NGs, weight= 'rad', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_id = {}\n",
    "\n",
    "for i, g in NGs.edges(): edge_id[(i,g)] = NGs[i][g]['streetID']\n",
    "\n",
    "edges_df = ic.dict_to_df([Eb, edge_id], [\"Eb\", \"streetID\"])\n",
    "edges_df.streetID = edges_df.streetID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp = pd.merge(edges_small, edges_df, left_on = 'streetID', right_on = 'streetID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesDual_small, edgesDual_small = ic.dual_gdf(nodes_small, edges_small, crs)\n",
    "# nodesDual_large, edgesDual_large = ic.dual_gdf(nodes_large, edges_large, crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesDual_small = nodesDual_small.drop('intersecting',axis=1)\n",
    "nodesDual_small.crs = crs\n",
    "nodesDual_small.to_file(folder_ouptut+city_name+'_experiment_nodesDual.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.scaling_columnDF(edgesDual_small, 'rad') # for combining with landmarkness\n",
    "edgesDual_small.crs = crs\n",
    "edgesDual_small.to_file(folder_ouptut+city_name+'_experiment_edgesDual.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dual graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_costs = ['rad', 'length', 'deg']\n",
    "DG_small = ic.get_dual_graph(nodesDual_small, edgesDual_small, edges_costs)\n",
    "# DG_large =  ic.get_dual_graph(nodesDual_large, edgesDual_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Betweenness - Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab = nx.betweenness_centrality(DG_small, weight ='angle', normalized=False)\n",
    "Ab_dict = ic.dual_id_dict(Ab, DG_small, 'streetID')\n",
    "Ab_df = ic.dict_to_df([Ab_dict], ['Ab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.merge(paths_tmp, Ab_df, left_on = \"streetID\", right_index=True, how='left')\n",
    "\n",
    "col = ['Eb', 'Ab']\n",
    "for i in col: ic.scaling_columnDF(paths, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitions - Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ['length', 'rad', 'False']\n",
    "subdvisions = []\n",
    "\n",
    "for i in weights:\n",
    "    partition = community.best_partition(DG_large, weight=i)\n",
    "    dct = ic.dual_id_dict(partition, DG_large, 'streetID')\n",
    "    subdvisions.append(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_df = ic.dict_to_df(subdvisions, [\"p_len\", \"p_rad\", 'p_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = pd.merge(edges_large, partitions_df, left_on= \"streetID\", right_index = True, how= 'left')\n",
    "districts.to_file(folder_ouptut+city_name+'_districts.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['natural_id'] = \"NA\"\n",
    "natural_id = 0 \n",
    "\n",
    "for row in paths.itertuples():\n",
    "\n",
    "    if (row[-1] != 'NA'): continue # if already assigned to a natural road\n",
    "   \n",
    "    ic.natural_roads(row[0], natural_id, \"fr\", paths, nodes) # assuming streetID = index\n",
    "    ic.natural_roads(row[0], natural_id, \"to\", paths, nodes) \n",
    "    natural_id = natural_id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.scaling_columnDF(paths, 'length')\n",
    "paths.crs = crs\n",
    "paths.to_file(folder_ouptut+city_name+'_experiment_paths.shp', driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
