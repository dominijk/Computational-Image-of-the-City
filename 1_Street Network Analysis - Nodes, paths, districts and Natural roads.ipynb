{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox, networkx as nx, matplotlib.cm as cm, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import functools\n",
    "import community\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg\n",
    "import time\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, mapping, MultiLineString\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "pd.set_option('precision', 10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_city_functions as ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise path, names, etc.\n",
    "\n",
    "city_name = 'London'\n",
    "folder_ouptut ='Outputs/'+city_name+'/'\n",
    "epsg = 27700\n",
    "crs = {'init': 'epsg:27700', 'no_defs': True}\n",
    "download = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the data by place or Loading shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a clean network shall be used, move below\n",
    "\n",
    "placeAnalysis = 'London Congestion Charge'\n",
    "placeLarger = 'Greater London (175342)'\n",
    "\n",
    "if download == True:\n",
    "    nodes_small, edges_small = ic.get_from_OSM(placeAnalysis)\n",
    "    nodes_large, edges_large = ic.get_from_OSM(placeLarger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_small = 'C:/Users/g_filo01/sciebo/GIS Data/London/OS_Roads_Working/OS_roads_final.shp'\n",
    "directory_large = 'C:/Users/g_filo01/sciebo/GIS Data/Boston/Street_Network/boston_sn_26986_clipped_8000_noHW.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_small, edges_small = ic.get_fromSHP(directory_small, epsg, crs)\n",
    "nodes_small, edges_small = ic.get_fromSHP(directory_small, epsg, crs, simplify = True, area = 2000)\n",
    "# nodes_large, edges_large = ic.get_fromSHP(directory_large, epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Street Network - gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes computation - Nodes\n",
    "## only area of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGs = ic.graph_fromGDF(nodes_small, edges_small)\n",
    "# NGl = ic.graph_fromGDF(nodes_large, edges_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bc = nx.betweenness_centrality(NGs, k=None, weight = 'length', normalized=False)\n",
    "Sc = ic.straightness_centrality(NGs, weight = 'length', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI = gpd.read_file('Outputs/POI.shp')\n",
    "POI = (gpd.read_file(folder_ouptut+'/'+city_name+'_POI.shp')).to_crs(epsg=epsg)\n",
    "\n",
    "index_geometry = nodes_small.columns.get_loc(\"geometry\")+1\n",
    "for row in nodes_small.itertuples():\n",
    "    \n",
    "    g = row[index_geometry] #geometry\n",
    "    fil = g.buffer(50)\n",
    "    \n",
    "    sindex = POI.sindex\n",
    "    possible_matches_index = list(sindex.intersection(fil.bounds))\n",
    "    possible_matches = POI.iloc[possible_matches_index]\n",
    "        \n",
    "    weight = len(possible_matches)\n",
    "    nodes_small.set_value(row[0], 'weight', weight)\n",
    "    \n",
    "for n in NGs.nodes():\n",
    "    NGs.node[n]['weight'] = nodes_small['weight'].loc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach Centrality\n",
    "Rc400 = ic.reach_centrality(NGs, weight = 'length', radius = 400) \n",
    "Rc600 = ic.reach_centrality(NGs, weight = 'length', radius = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Betweenness Centrality\n",
    "Bc600 = ic.local_betweenness_centrality(NGs, weight = 'length', radius = 600) \n",
    "Bc400 = ic.local_betweenness_centrality(NGs, weight = 'length', radius = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = ic.dict_to_df([Bc, Sc, Rc400, Rc600, Bc400, Bc600], ['Bc', 'Sc', 'Rc400', 'Rc600', 'Bc400', 'Bc600'])\n",
    "nodes = pd.merge(nodes_small, nodes_df, left_on= \"nodeID\", right_index = True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Bc', 'Sc', 'Rc400', 'Rc600', 'Bc400', 'Bc600']\n",
    "for i in col: ic.scaling_columnDF(nodes, i)\n",
    "nodes['height'] = 2 # for 3d visibility analysis\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes =nodes.drop(['coordinates'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.crs = crs\n",
    "nodes.to_file(folder_ouptut+city_name+'_experiment_nodes.shp', driver='ESRI Shapefile')\n",
    "# nodes_small.to_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb = nx.edge_betweenness_centrality(NGs, weight= 'rad', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_id={}\n",
    "\n",
    "for i, g in NGs.edges(): edge_id[(i,g)] = NGs[i][g]['streetID']\n",
    "\n",
    "edges_df = ic.dict_to_df([Eb, edge_id], [\"Eb\", \"streetID\"])\n",
    "edges_df.streetID = edges_df.streetID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp = pd.merge(edges_small, edges_df, left_on = 'streetID', right_on = 'streetID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesDual_small, edgesDual_small = ic.dual_gdf(nodes_small, edges_small, crs)\n",
    "# nodesDual_large, edgesDual_large = ic.dual_gdf(nodes_large, edges_large, crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesDual_small = nodesDual_small.drop('intersecting',axis=1)\n",
    "nodesDual_small.to_file(folder_ouptut+city_name+'_experiment_nodesDual.shp', driver='ESRI Shapefile')\n",
    "nodesDual_small.crs = crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesDual_small.crs = crs\n",
    "ic.scaling_columnDF(edgesDual_small, 'rad')\n",
    "edgesDual_small.to_file(folder_ouptut+city_name+'_experiment_edgesDual.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dual graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG_small = ic.get_dual_graph(nodesDual_small, edgesDual_small)\n",
    "# DG_large =  ic.get_dual_graph(nodesDual_large, edgesDual_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Betweenness - Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab = nx.betweenness_centrality(DG_small, weight ='angle', normalized=False)\n",
    "Ab_dict = ic.dual_id_dict(Ab, DG_small, 'streetID')\n",
    "Ab_df = ic.dict_to_df([Ab_dict], ['Ab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>streetID</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>key</th>\n",
       "      <th>length</th>\n",
       "      <th>Eb</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Eb_sc</th>\n",
       "      <th>Ab_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINESTRING (532249.0000001296 181331.999999489...</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1879</td>\n",
       "      <td>0</td>\n",
       "      <td>140.4154724299</td>\n",
       "      <td>4190.3168683692</td>\n",
       "      <td>7723.7319543177</td>\n",
       "      <td>0.0143185994</td>\n",
       "      <td>0.0138231420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINESTRING (529822.0000001182 180202.999999543...</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>1874</td>\n",
       "      <td>0</td>\n",
       "      <td>224.1354551381</td>\n",
       "      <td>160875.8507094269</td>\n",
       "      <td>300023.0866678497</td>\n",
       "      <td>0.5501073763</td>\n",
       "      <td>0.5369505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINESTRING (530035.700000119 180237.9499995388...</td>\n",
       "      <td>2</td>\n",
       "      <td>1314</td>\n",
       "      <td>1874</td>\n",
       "      <td>0</td>\n",
       "      <td>103.4004536549</td>\n",
       "      <td>1879.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0064150131</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINESTRING (530063.0700001192 180298.799999538...</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>89.5560431350</td>\n",
       "      <td>15668.9423240576</td>\n",
       "      <td>25914.5608577879</td>\n",
       "      <td>0.0535699491</td>\n",
       "      <td>0.0463792189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINESTRING (530196.8200001197 180345.849999534...</td>\n",
       "      <td>4</td>\n",
       "      <td>1043</td>\n",
       "      <td>1736</td>\n",
       "      <td>0</td>\n",
       "      <td>285.7831740934</td>\n",
       "      <td>191837.3097794528</td>\n",
       "      <td>358085.3934174514</td>\n",
       "      <td>0.6559805982</td>\n",
       "      <td>0.6408644520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  streetID     u     v  \\\n",
       "0  LINESTRING (532249.0000001296 181331.999999489...         0   256  1879   \n",
       "1  LINESTRING (529822.0000001182 180202.999999543...         1  1399  1874   \n",
       "2  LINESTRING (530035.700000119 180237.9499995388...         2  1314  1874   \n",
       "3  LINESTRING (530063.0700001192 180298.799999538...         3    85    43   \n",
       "4  LINESTRING (530196.8200001197 180345.849999534...         4  1043  1736   \n",
       "\n",
       "   key          length                 Eb                 Ab         Eb_sc  \\\n",
       "0    0  140.4154724299    4190.3168683692    7723.7319543177  0.0143185994   \n",
       "1    0  224.1354551381  160875.8507094269  300023.0866678497  0.5501073763   \n",
       "2    0  103.4004536549    1879.0000000000       0.0000000000  0.0064150131   \n",
       "3    0   89.5560431350   15668.9423240576   25914.5608577879  0.0535699491   \n",
       "4    0  285.7831740934  191837.3097794528  358085.3934174514  0.6559805982   \n",
       "\n",
       "          Ab_sc  \n",
       "0  0.0138231420  \n",
       "1  0.5369505000  \n",
       "2  0.0000000000  \n",
       "3  0.0463792189  \n",
       "4  0.6408644520  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = pd.merge(paths_tmp, Ab_df, left_on = \"streetID\", right_index=True, how='left')\n",
    "\n",
    "col = ['Eb', 'Ab']\n",
    "for i in col: ic.scaling_columnDF(paths, i)\n",
    "\n",
    "paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitions - Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ['length', 'rad', 'False']\n",
    "subdvisions = []\n",
    "\n",
    "for i in weights:\n",
    "    partition = community.best_partition(DG_large, weight=i)\n",
    "    dct = ic.dual_id_dict(partition, DG_large, 'streetID')\n",
    "    subdvisions.append(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_df = ic.dict_to_df(subdvisions, [\"p_len\", \"p_rad\", 'p_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges_large' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b4d642544ebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistricts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_large\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"streetID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdistricts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'edges_large' is not defined"
     ]
    }
   ],
   "source": [
    "districts = pd.merge(edges_large, partitions_df, left_on= \"streetID\", right_index = True, how= 'left')\n",
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.to_file(folder_ouptut+city_name+'_districts.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['natural_id'] = \"NA\"\n",
    "natural_id = 0 \n",
    "\n",
    "for row in paths.itertuples():\n",
    "\n",
    "    if (row[-1] != 'NA'): continue # if already assigned to a natural road\n",
    "   \n",
    "    ic.natural_roads(row[0], natural_id, \"fr\", paths, nodes) # assuming streetID = index\n",
    "    ic.natural_roads(row[0], natural_id, \"to\", paths, nodes) \n",
    "    natural_id = natural_id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.crs = crs\n",
    "paths.to_file(folder_ouptut+city_name+'_experiment_paths.shp', driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
