{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox, networkx as nx, matplotlib.cm as cm, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "import functools\n",
    "import community\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg\n",
    "import time\n",
    "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, mapping\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from shapely.ops import cascaded_union\n",
    "pd.set_option('precision', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_city_functions as ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing landmarkness on paths and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise path, names, etc.\n",
    "\n",
    "city_name = 'London'\n",
    "folder_ouptut ='Outputs/'+city_name+'/'\n",
    "epsg = 27700\n",
    "crs = {'init': 'epsg:27700', 'no_defs': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try reading nodes, paths, landmarks and sight_lines\n",
    "# At this point, every element has already been extracted\n",
    "\n",
    "nodes = gpd.read_file(folder_ouptut+city_name+'_experiment_nodes.shp', driver='ESRI Shapefile')\n",
    "paths = gpd.read_file(folder_ouptut+city_name+'_experiment_paths.shp', driver='ESRI Shapefile')\n",
    "landmarks = gpd.read_file(folder_ouptut+city_name+'_landmarks.shp', driver='ESRI Shapefile')\n",
    "sight_lines = gpd.read_file(folder_ouptut+city_name+'_sight_lines.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesAll = gpd.read_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['coordinates'] = nodes[['x', 'y']].apply(tuple, axis=1)\n",
    "nodesAll['coordinates'] = nodesAll[['x', 'y']].apply(tuple, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesT = pd.merge(nodes, nodesAll[['nodeID','coordinates']], left_on = 'coordinates', right_on = 'coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesT['nodeID'] = nodesT['nodeID_y'] \n",
    "nodesT.drop(['nodeID_x', 'nodeID_y', 'coordinates'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>weight</th>\n",
       "      <th>Bc</th>\n",
       "      <th>Sc</th>\n",
       "      <th>Rc400</th>\n",
       "      <th>Rc600</th>\n",
       "      <th>Bc400</th>\n",
       "      <th>Bc600</th>\n",
       "      <th>Bc_sc</th>\n",
       "      <th>Sc_sc</th>\n",
       "      <th>Rc400_sc</th>\n",
       "      <th>Rc600_sc</th>\n",
       "      <th>Bc400_sc</th>\n",
       "      <th>Bc600_sc</th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nodeID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>531336.0000001253</td>\n",
       "      <td>180096.9999995109</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27035.0</td>\n",
       "      <td>1476.3252335184</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>0.0899565440</td>\n",
       "      <td>0.6738782619</td>\n",
       "      <td>0.1075737265</td>\n",
       "      <td>0.1179430872</td>\n",
       "      <td>0.0555099809</td>\n",
       "      <td>0.0885258359</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (531336.0000001253 180096.9999995109)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530201.0000001198</td>\n",
       "      <td>181209.9999995350</td>\n",
       "      <td>37.0</td>\n",
       "      <td>93839.0</td>\n",
       "      <td>1544.0025763110</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>7005.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.3122408779</td>\n",
       "      <td>0.8331905585</td>\n",
       "      <td>0.5333445040</td>\n",
       "      <td>0.6374782688</td>\n",
       "      <td>0.1543614985</td>\n",
       "      <td>0.2279635258</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (530201.0000001198 181209.999999535)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>531996.0000001284</td>\n",
       "      <td>181571.9999994949</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1393.6939741797</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.4793644829</td>\n",
       "      <td>0.0474195710</td>\n",
       "      <td>0.0957086650</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (531996.0000001284 181571.9999994949)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531725.0000001271</td>\n",
       "      <td>180274.9999995017</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>1469.6319448975</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.0275942156</td>\n",
       "      <td>0.6581222771</td>\n",
       "      <td>0.1005361930</td>\n",
       "      <td>0.1209625766</td>\n",
       "      <td>0.0877768663</td>\n",
       "      <td>0.1050531915</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (531725.0000001271 180274.9999995017)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529874.0000001183</td>\n",
       "      <td>180764.9999995416</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>1511.7207881573</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>7592.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0059860116</td>\n",
       "      <td>0.7571993095</td>\n",
       "      <td>0.5754021448</td>\n",
       "      <td>0.6911885808</td>\n",
       "      <td>0.0161334427</td>\n",
       "      <td>0.0237462006</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (529874.0000001183 180764.9999995416)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x                  y  weight       Bc               Sc  \\\n",
       "0  531336.0000001253  180096.9999995109     6.0  27035.0  1476.3252335184   \n",
       "1  530201.0000001198  181209.9999995350    37.0  93839.0  1544.0025763110   \n",
       "2  531996.0000001284  181571.9999994949     5.0      0.0  1393.6939741797   \n",
       "3  531725.0000001271  180274.9999995017    29.0   8293.0  1469.6319448975   \n",
       "4  529874.0000001183  180764.9999995416    37.0   1799.0  1511.7207881573   \n",
       "\n",
       "    Rc400   Rc600   Bc400   Bc600         Bc_sc         Sc_sc      Rc400_sc  \\\n",
       "0   643.0  1327.0   812.0   466.0  0.0899565440  0.6738782619  0.1075737265   \n",
       "1  3184.0  7005.0  2258.0  1200.0  0.3122408779  0.8331905585  0.5333445040   \n",
       "2   284.0  1084.0     0.0     0.0  0.0000000000  0.4793644829  0.0474195710   \n",
       "3   601.0  1360.0  1284.0   553.0  0.0275942156  0.6581222771  0.1005361930   \n",
       "4  3435.0  7592.0   236.0   125.0  0.0059860116  0.7571993095  0.5754021448   \n",
       "\n",
       "       Rc600_sc      Bc400_sc      Bc600_sc  height  \\\n",
       "0  0.1179430872  0.0555099809  0.0885258359       2   \n",
       "1  0.6374782688  0.1543614985  0.2279635258       2   \n",
       "2  0.0957086650  0.0000000000  0.0000000000       2   \n",
       "3  0.1209625766  0.0877768663  0.1050531915       2   \n",
       "4  0.6911885808  0.0161334427  0.0237462006       2   \n",
       "\n",
       "                                      geometry  nodeID  \n",
       "0  POINT (531336.0000001253 180096.9999995109)       2  \n",
       "1   POINT (530201.0000001198 181209.999999535)       3  \n",
       "2  POINT (531996.0000001284 181571.9999994949)       5  \n",
       "3  POINT (531725.0000001271 180274.9999995017)       6  \n",
       "4  POINT (529874.0000001183 180764.9999995416)       7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodesT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g_filo01\\sciebo\\scripts\\Image of the City\\image_city_functions.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[i+'_sc'] = (df[i]-df[i].min())/(df[i].max()-df[i].min())\n",
      "C:\\Users\\g_filo01\\sciebo\\scripts\\Image of the City\\image_city_functions.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if (inverse == True): df[i+'_sc'] = 1-(df[i]-df[i].min())/(df[i].max()-df[i].min())\n",
      "C:\\Users\\g_filo01\\sciebo\\scripts\\Image of the City\\image_city_functions.py:884: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  LL['vScore']= (LL['fac_sc']*30 + LL['height_sc']*20 + LL['vis_sc']*50)/100\n",
      "C:\\Users\\g_filo01\\sciebo\\scripts\\Image of the City\\image_city_functions.py:885: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  LL['sScore']= (LL['ext_sc']*30 + LL['neigh_sc']*20 + LL['prom_sc']*30 + LL['road_sc']*20)/100\n",
      "C:\\Users\\g_filo01\\sciebo\\scripts\\Image of the City\\image_city_functions.py:890: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  LL['lScore']=(LL['vScore_sc']*20 + LL['sScore_sc']*30 + LL['cult_sc']*10 + LL['prag_sc']*40)/100\n"
     ]
    }
   ],
   "source": [
    "nodes = ic.decision_score(nodesT, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ic.distant_score(nodes, landmarks, sight_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale to have higher values for lower values and viceversa\n",
    "col = ['DD', 'DE']\n",
    "\n",
    "for i in col: ic.scaling_columnDF(nodes, i, inverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning scores to edges, based on the best reassuring landmark along each of them\n",
    "\n",
    "# spatial_index = landmarks.sindex\n",
    "# paths['reass'] = 0.0\n",
    "\n",
    "# for row in paths.itertuples():\n",
    "    \n",
    "#     g = row[-2] #geometry\n",
    "#     fil = g.buffer(25)    \n",
    "    \n",
    "#     possible_matches_index = list(spatial_index.intersection(fil.bounds))\n",
    "#     possible_matches = landmarks.iloc[possible_matches_index]\n",
    "#     precise_matches = possible_matches[possible_matches.intersects(fil)]\n",
    "\n",
    "#     if (len(precise_matches)==0): continue\n",
    "    \n",
    "#     precise_matches = precise_matches.sort_values(by='score_scal', ascending=False).reset_index()\n",
    "#     score = precise_matches['score_scal'].loc[0]\n",
    "#     paths.set_value(row[0], 'reass', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning nodes' score to each edge\n",
    "\n",
    "paths['nS_vis'] = 0.0\n",
    "paths['nS_dp'] = 0.0\n",
    "\n",
    "for row in paths.itertuples():\n",
    "    u = row[2]\n",
    "    v = row[3]\n",
    "    nodes_path = nodes[nodes['nodeID'].isin([u,v])]\n",
    "    paths.set_value(row[0], 'nS_vis', nodes_path['dp'].sum())\n",
    "    paths.set_value(row[0], 'nS_dp', nodes_path['dist'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling raw scores as before\n",
    "col = ['reass', 'nS_vis', 'nS_dp'] \n",
    "\n",
    "for i in col:\n",
    "    inverse_scaling(paths, i)\n",
    "\n",
    "# scaling distances\n",
    "scaling(paths, 'length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['land'] = paths['reass_sc']+ paths['nS_vis_sc'] + paths['nS_dp_sc']\n",
    "scaling(paths, 'land')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['dist&land'] = paths['length_sc']+paths['land_sc']\n",
    "paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing edge betweenness \n",
    "## Primal graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.drop(nodes[['visible_landmarks']],axis=1)\n",
    "nodes.gdf_name = 'Nodes_list' #for OSMNx\n",
    "paths.gdf_name = 'Edges_list' #for OSMNx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.gdfs_to_graph(nodes, paths)\n",
    "t = G.nodes()\n",
    "pos = {}\n",
    "\n",
    "for l, item in enumerate(t): pos[l] = (t[l]['x'],t[l]['y'])\n",
    "\n",
    "Ng = nx.Graph() #Empty graph\n",
    "Ng = Ng.to_undirected()\n",
    "Ng.add_nodes_from(pos.keys()) #Add nodes preserving coordinates\n",
    "\n",
    "for i, item in enumerate(Ng.nodes()):\n",
    "    Ng.node[i]['x']=pos[i][0]\n",
    "    Ng.node[i]['y']=pos[i][1]\n",
    "\n",
    "for i, item in enumerate(G.edges()):\n",
    "    Ng.add_edge(item[0], item[1])\n",
    "    Ng[item[0]][item[1]]['land_sc']=G[item[0]][item[1]][0]['land_sc']\n",
    "    Ng[item[0]][item[1]]['dist&land']=G[item[0]][item[1]][0]['dist&land']\n",
    "    Ng[item[0]][item[1]]['streetID']=G[item[0]][item[1]][0]['streetID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lb = nx.edge_betweenness_centrality(Ng, weight='land_sc', normalized=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELb = nx.edge_betweenness_centrality(Ng, weight='dist&land', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(list_dict, list_col):\n",
    "    \n",
    "    df = pd.DataFrame(list_dict).T\n",
    "    df.columns = ['d{}'.format(i) for i, col in enumerate(df, 1)]\n",
    "    df.columns = list_col\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_id={}\n",
    "for i, g in Ng.edges(): edge_id[(i,g)]=Ng[i][g]['streetID']\n",
    "\n",
    "edges_df = to_df([Lb, ELb, edge_id], [\"Lb\", \"ELb\",\"streetID\"])\n",
    "edges_df.streetID = edges_df.streetID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp = pd.merge(paths, edges_df, left_on = 'streetID', right_on = 'streetID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGDF(gdf, column, title):\n",
    "    f, ax = plt.subplots(1, figsize=(15, 15))\n",
    "    gdf.plot(ax=ax, column=column, cmap='OrRd', scheme='Fisher_Jenks', linewidth=0.5, legend=True)\n",
    "    f.suptitle(title)\n",
    "    plt.axis('equal')\n",
    "    leg = ax.get_legend()\n",
    "    leg.set_bbox_to_anchor((0., 0., 0.2, 0.2))\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "nodes.plot(ax=ax, column='dist', cmap='OrRd', scheme='Fisher_Jenks', markersize=5)\n",
    "plt.axis('equal')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotGDF(paths_tmp,'Eb', 'Euclidean Betweenness')\n",
    "plotGDF(paths_tmp,'Lb', 'Landmark Betweenness')\n",
    "plotGDF(paths_tmp,'ELb', 'Landmark and distance Betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dual = gpd.read_file(folder_ouptut+city_name+'_nodesDual.shp', driver='ESRI Shapefile')\n",
    "edges_dual = gpd.read_file(folder_ouptut+city_name+'_edgesDual.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning landmark scores to links between centroids (this is artificial)\n",
    "\n",
    "edges_dual.u = edges_dual.u.astype(int)\n",
    "edges_dual.v = edges_dual.v.astype(int)\n",
    "edges_dual.key = edges_dual.key.astype(int)\n",
    "\n",
    "for row in edges_dual.itertuples():\n",
    "    landmarkness_u = paths['land'][paths.streetID==row[1]].loc[row[1]] #row[1]==u\n",
    "    landmarkness_v = paths['land'][paths.streetID==row[2]].loc[row[2]] #row[2]==v\n",
    "    landmarkness = landmarkness_u+landmarkness_v\n",
    "    edges_dual.set_value(row[0], 'land', landmarkness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling(edges_dual, 'rad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling raw scores and deviation\n",
    "\n",
    "scaling(edges_dual, 'land')  \n",
    "edges_dual['angle&land'] = edges_dual['rad_sc']+edges_dual['land_sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dual.gdf_name = 'Dual_list'\n",
    "Gr = ox.gdfs_to_graph(nodes_dual, edges_dual)\n",
    "    \n",
    "n = Gr.nodes()\n",
    "pos = {}\n",
    "    \n",
    "print(len(n))\n",
    "for l, item in enumerate(n): pos[l] = (n[l]['x'],n[l]['y'],n[l]['streetID'])\n",
    "        \n",
    "DG = nx.Graph() #Empty graph\n",
    "DG = DG.to_undirected()\n",
    "DG.add_nodes_from(pos.keys()) #Add nodes preserving coordinates\n",
    "    \n",
    "for i, item in enumerate(DG.nodes()):\n",
    "    DG.node[i]['x']=pos[i][0]\n",
    "    DG.node[i]['y']=pos[i][1]\n",
    "    DG.node[i]['streetID']=pos[i][2]\n",
    "        \n",
    "for i, item in enumerate(Gr.edges()):\n",
    "    DG.add_edge(item[0], item[1])\n",
    "    DG[item[0]][item[1]]['angle&land'] = Gr[item[0]][item[1]][0]['angle&land']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALb = nx.betweenness_centrality(DG, weight='angle&land', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_dict(ed, graph):\n",
    "    \n",
    "    view = ed.items()\n",
    "    ed_list = list(view)\n",
    "    ed_dict = {}\n",
    "\n",
    "    for p in ed_list:\n",
    "        ed_dict[graph.node[p[0]]['streetID']]=p[1] #streetID and Edge betweenness\n",
    "        \n",
    "    return(ed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALb_dict = id_dict(ALb, DG)\n",
    "ALb_df = to_df([ALb_dict], [\"ALb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp = pd.merge(paths_tmp, ALb_df, left_on=\"streetID\", right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(paths_tmp,'Ab', 'Angular Betweenness')\n",
    "plot(paths_tmp,'ALb', 'Angular-Landmark Betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp.to_file(folder_ouptut+city_name+'_paths.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_file(folder_ouptut+city_name+'_nodes.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians = pd.read_csv(\"C:/Users/g_filo01/sciebo/GIS Data/Simulation/pedestrians_eucl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colPed = [\"euclidean\", \"topological\", \"angular\", \"landmark\", \"euclideanLand\", \"topologicalLand\", \"angularLand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data = pd.merge(paths_tmp, pedestrians, left_on=\"streetID\", right_on=\"streetID\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_data['euclideanDiff']=paths_data['euclidean']-paths_data['euclideanLand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotGDF(paths_data,\"euclidean\",\"euclidean\")\n",
    "# plotGDF(paths_data,\"topological\",\"topological\")\n",
    "# plotGDF(paths_data,\"angular\",\"angular\")\n",
    "plotGDF(paths_data,\"euclideanLand\",\"euclideanLand\")\n",
    "plotGDF(paths_data,\"euclideanDiff\",\"diff\")\n",
    "# plotGDF(paths_data,\"topologicalLand\",\"topologicalLand\")\n",
    "# plotGDF(paths_data,\"angularLand\",\"angularLand\")\n",
    "# plotGDF(paths_data,\"landmark\",\"landmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in colPed:\n",
    "    print(i)\n",
    "    plotGDF(paths_data, colPed, colPed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
